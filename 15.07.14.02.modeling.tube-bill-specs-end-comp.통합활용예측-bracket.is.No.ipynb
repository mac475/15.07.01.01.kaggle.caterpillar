{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\", \"malgun gothic\";\n",
       "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "    }\n",
       "//    div.cell{\n",
       "//        width: 100%;\n",
       "//    }\n",
       "    // 아래의 div.container는 내가 임의로 추가한 style임\n",
       "//    div.container{\n",
       "//        width: 105%;\n",
       "//    }\n",
       "    ul {\n",
       "        line-height: 100%;\n",
       "        font-size: 100%;\n",
       "    }\n",
       "    li {\n",
       "        margin-bottom: 0.5em;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif, \"malgun gothic\";\n",
       "    }\n",
       "    h4{\n",
       "        margin-top: 12px;\n",
       "//        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "//        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        font-family: malgun gothic;\n",
       "        line-height: 140%;\n",
       "//        font-size: 100%;\n",
       "//        width: 100%;\n",
       "//        margin-left:auto;\n",
       "//        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "/*    .prompt{\n",
       "        display: None;\n",
       "    }*/\n",
       "    .text_cell_render h5 {\n",
       "        font-family: malgun gothic;\n",
       "        font-weight: 300;\n",
       "        font-size: 16pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: 0.5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "//                \"HTML-CSS\": {\n",
       "//                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "//                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mac475의 ipython 표준 style을 적용함\n",
    "from IPython.core.display import HTML\n",
    "styles = open(\"../styles/custom.css\", \"r\").read()\n",
    "HTML( styles )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0. Mode 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode = True\n",
    "# mode = False\n",
    "\n",
    "# bracket_pricing별로 구분한다\n",
    "# bracket = 'Yes'\n",
    "bracket = 'No'\n",
    "# bracket = 'All'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0. Dataset 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv( './dataset/train_set.csv' )    # data를 읽어들인다.\n",
    "df_test = pd.read_csv( './dataset/test_set.csv' )    # data를 읽어들인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if bracket == 'Yes' :\n",
    "    # bracket_pricing == Yes인 경우만\n",
    "    df_train = df_train[ df_train[ 'bracket_pricing' ] == 'Yes' ]\n",
    "elif bracket == 'No' :\n",
    "    # bracket_pricing == No인 경우만\n",
    "    df_train = df_train[ df_train[ 'bracket_pricing' ] == 'No' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Feature 추출 function\n",
    "* quote_date 활용하여 year, month, day 확보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def extract_year_month_day_from_quote_date( p_df ) :    # quote date로부터 연도, 월, 날짜를 추출\n",
    "    p_df[ 'quote_date' ] = pd.to_datetime( p_df[ 'quote_date' ] )    # string을 datetime으로 형변환\n",
    "    p_df[ 'year' ] = p_df[ 'quote_date' ].dt.year    # 연도\n",
    "    p_df[ 'month' ] = p_df[ 'quote_date' ].dt.month    # 월\n",
    "    p_df[ 'day' ] = p_df[ 'quote_date' ].dt.day    # 일\n",
    "    \n",
    "    return p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_string_date( p_df ) :    # 일자정보를 string으로 변경\n",
    "    y = p_df[ 'year' ]\n",
    "    m = p_df[ 'month' ]\n",
    "    d = p_df[ 'day' ]\n",
    "    \n",
    "    str_y = ''\n",
    "    str_m = ''\n",
    "    str_d = ''\n",
    "    \n",
    "    str_y = str( y )\n",
    "    str_m = ''\n",
    "    if m < 10 :\n",
    "        str_m = '0' + str( m )\n",
    "    else :\n",
    "        str_m = str( m )\n",
    "    str_d = ''\n",
    "    if d < 10 :\n",
    "        str_d = '0' + str( d )\n",
    "    else :\n",
    "        str_d = str( d )\n",
    "    \n",
    "    return str_y + str_m + str_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Label Encoding function\n",
    "* 현재, train/ test dataset과 tube dataset과 merge하는 case까지 반영하여 encoder 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tube_assembly_id      3930\n",
       "supplier              3930\n",
       "quote_date            3930\n",
       "annual_usage          3930\n",
       "min_order_quantity    3930\n",
       "bracket_pricing       3930\n",
       "quantity              3930\n",
       "cost                  3930\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# le_bracket_pricing = preprocessing.LabelEncoder()\n",
    "le_supplier = preprocessing.LabelEncoder()\n",
    "le_material_id = preprocessing.LabelEncoder()\n",
    "le_date = preprocessing.LabelEncoder()\n",
    "\n",
    "le_yn = preprocessing.LabelEncoder()\n",
    "le_yn.fit( [ 'Y', 'N' ] )\n",
    "\n",
    "\n",
    "le_end = preprocessing.LabelEncoder()\n",
    "df_end = pd.read_csv( './dataset/01.original.dataset/tube_end_form.csv' )\n",
    "le_end.fit( df_end[ 'end_form_id' ] )\n",
    "df_end = ''\n",
    "\n",
    "\n",
    "le_component_id = preprocessing.LabelEncoder()    # component의 경우, master dataset이 별도로 존재하므로\n",
    "df_components = pd.read_csv( './dataset/02.ml.verified.dataset/components.verified.csv' )\n",
    "le_component_id.fit( df_components[ 'component_id' ] )\n",
    "\n",
    "\n",
    "le_spec_id = preprocessing.LabelEncoder()    # spec의 경우, spec meta dataset을 별도로 생성했음\n",
    "df_spec_meta = pd.read_csv( './dataset/01.original.dataset/spec_meta.csv' )\n",
    "le_spec_id.fit( df_spec_meta[ 'spec' ] )\n",
    "df_spec_meta = ''\n",
    "\n",
    "\n",
    "le_component_mac475 = preprocessing.LabelEncoder()\n",
    "le_component_mac475.fit( df_components[ 'component_mac475' ] )\n",
    "\n",
    "\n",
    "le_component_type_id = preprocessing.LabelEncoder()\n",
    "le_component_type_id.fit( df_components[ 'component_type_id' ] )\n",
    "df_components = ''\n",
    "\n",
    "\n",
    "le_type_end = preprocessing.LabelEncoder()\n",
    "df_type_end = pd.read_csv( './dataset/01.original.dataset/type_end_form.csv' )\n",
    "le_type_end.fit( df_type_end[ 'end_form_id' ] )\n",
    "df_type_end = ''\n",
    "\n",
    "\n",
    "le_connection = preprocessing.LabelEncoder()\n",
    "df_connection = pd.read_csv( './dataset/01.original.dataset/type_connection.csv' )\n",
    "le_connection.fit( df_connection[ 'connection_type_id' ] )\n",
    "df_connection = ''\n",
    "\n",
    "\n",
    "le_yn_none = preprocessing.LabelEncoder()\n",
    "le_yn_none.fit( [ 'Y', 'N', 'NONE' ] )\n",
    "\n",
    "\n",
    "le_boss_type = preprocessing.LabelEncoder()\n",
    "le_boss_type.fit( [ 'Boss', 'Stud', 'NONE' ] )\n",
    "\n",
    "\n",
    "le_elbow_mj_class_code = preprocessing.LabelEncoder()\n",
    "le_elbow_mj_class_code.fit( [ 'N', 'MJ-001', 'MJ-003', 'MJ-005', 'MJ-006', 'NONE' ] )\n",
    "\n",
    "le_boss_outside_shape = preprocessing.LabelEncoder()\n",
    "le_boss_outside_shape.fit( [ 'Round', 'Hex', 'NONE' ] )\n",
    "\n",
    "\n",
    "le_boss_base_type = preprocessing.LabelEncoder()\n",
    "le_boss_base_type.fit( [ 'Flat Bottom', 'Saddle', 'Shoulder', 'NONE' ] )\n",
    "\n",
    "def executeLabelEncoding( p_df, is_init ) :\n",
    "    if is_init == True :    # training dataset인 경우, label encoder 생성 및 fitting 수행\n",
    "        p_df[ 'supplier' ] = le_supplier.fit_transform( p_df[ 'supplier' ] )\n",
    "        p_df[ 'material_id' ] = le_material_id.fit_transform( p_df[ 'material_id' ] )\n",
    "        p_df[ 'date' ] = le_date.fit_transform( p_df[ 'date' ] )\n",
    "    else :\n",
    "        p_df[ 'supplier' ] = le_supplier.transform( p_df[ 'supplier' ] )\n",
    "        p_df[ 'material_id' ] = le_material_id.transform( p_df[ 'material_id' ] )\n",
    "        p_df[ 'date' ] = le_date.transform( p_df[ 'date' ] )\n",
    "        \n",
    "    # 무조건 수행\n",
    "    p_df[ 'is_annual' ] = le_yn.transform( p_df[ 'is_annual' ] )\n",
    "    p_df[ 'bracket_pricing' ] = le_yn.transform( p_df[ 'bracket_pricing' ] )\n",
    "    \n",
    "    # tube/material_id == null을 tube만 사용예측시 적용, bill/ spec 같이 사용예측시 주석처리\n",
    "#     p_df[ 'end_a_1x' ] = le_yn.transform( p_df[ 'end_a_1x' ] )\n",
    "#     p_df[ 'end_a_2x' ] = le_yn.transform( p_df[ 'end_a_2x' ] )\n",
    "#     p_df[ 'end_x_1x' ] = le_yn.transform( p_df[ 'end_x_1x' ] )\n",
    "#     p_df[ 'end_x_2x' ] = le_yn.transform( p_df[ 'end_x_2x' ] )\n",
    "    \n",
    "    p_df[ 'end_a' ] = le_end.transform( p_df[ 'end_a' ] )\n",
    "    p_df[ 'end_x' ] = le_end.transform( p_df[ 'end_x' ] )\n",
    "\n",
    "    for i in range( 1, 9 ) :    # bill_of_materials에서 merge된 component_id_1~8을 label encoding 수행\n",
    "        comp_str = 'component_id_' + str( i )\n",
    "        p_df[ comp_str ] = le_component_id.transform( p_df[ comp_str ] )\n",
    "\n",
    "    for i in range( 1, 11 ) :    # specs에서 merge된 spec1~10을 label encoding 수행\n",
    "        spec_str = 'spec' + str( i )\n",
    "        p_df[ spec_str ] = le_spec_id.transform( p_df[ spec_str ] )                \n",
    "        \n",
    "    p_df[ 'forming_x' ] = le_yn.transform( p_df[ 'forming_x' ] )\n",
    "    p_df[ 'forming_y' ] = le_yn.transform( p_df[ 'forming_y' ] )\n",
    "    \n",
    "    \n",
    "    comp_list = [ 'x' ]\n",
    "    for v in comp_list :\n",
    "        v = ''\n",
    "        p_df[ 'component_type_id' + v ] = le_component_type_id.transform( p_df[ 'component_type_id' + v ] )\n",
    "        p_df[ 'component_mac475' + v ] = le_component_mac475.transform( p_df[ 'component_mac475' + v ] )\n",
    "\n",
    "\n",
    "        p_df[ 'adaptor_end_form_id_1' + v ] = le_type_end.transform( p_df[ 'adaptor_end_form_id_1' + v ] )\n",
    "        p_df[ 'adaptor_connection_type_id_1' + v ] = le_connection.transform( p_df[ 'adaptor_connection_type_id_1' + v ] )\n",
    "        p_df[ 'adaptor_end_form_id_2' + v ] = le_type_end.transform( p_df[ 'adaptor_end_form_id_2' + v ] )\n",
    "        p_df[ 'adaptor_connection_type_id_2' + v ] = le_connection.transform( p_df[ 'adaptor_connection_type_id_2' + v ] )\n",
    "        p_df[ 'adaptor_unique_feature' + v ] = le_yn_none.transform( p_df[ 'adaptor_unique_feature' + v ] )\n",
    "        p_df[ 'adaptor_orientation' + v ] = le_yn_none.transform( p_df[ 'adaptor_orientation' + v ] )\n",
    "\n",
    "\n",
    "        p_df[ 'boss_type' + v ] = le_boss_type.transform( p_df[ 'boss_type' + v ] )\n",
    "        p_df[ 'boss_connection_type_id' + v ] = le_connection.transform( p_df[ 'boss_connection_type_id' + v ] )\n",
    "        p_df[ 'boss_outside_shape' + v ] = le_boss_outside_shape.transform( p_df[ 'boss_outside_shape' + v ] )\n",
    "        p_df[ 'boss_base_type' + v ] = le_boss_base_type.transform( p_df[ 'boss_base_type' + v ] )\n",
    "        p_df[ 'boss_groove' + v ] = le_yn_none.transform( p_df[ 'boss_groove' + v ] )\n",
    "        p_df[ 'boss_unique_feature' + v ] = le_yn_none.transform( p_df[ 'boss_unique_feature' + v ] )\n",
    "        p_df[ 'boss_orientation' + v ] = le_yn_none.transform( p_df[ 'boss_orientation' + v ] )\n",
    "\n",
    "\n",
    "        p_df[ 'elbow_mj_class_code' + v ] = le_elbow_mj_class_code.transform( p_df[ 'elbow_mj_class_code' + v ] )\n",
    "        p_df[ 'elbow_mj_plug_class_code' + v ] = le_elbow_mj_class_code.transform( p_df[ 'elbow_mj_plug_class_code' + v ] )\n",
    "        p_df[ 'elbow_groove' + v ] = le_yn_none.transform( p_df[ 'elbow_groove' + v ] )\n",
    "        p_df[ 'elbow_unique_feature' + v ] = le_yn_none.transform( p_df[ 'elbow_unique_feature' + v ] )\n",
    "        p_df[ 'elbow_orientation' + v ] = le_yn_none.transform( p_df[ 'elbow_orientation' + v ] )\n",
    "\n",
    "        p_df[ 'float_orientation' + v ] = le_yn_none.transform( p_df[ 'float_orientation' + v ] )\n",
    "\n",
    "        p_df[ 'hfl_corresponding_shell' + v ] = le_yn_none.transform( p_df[ 'hfl_corresponding_shell' + v ] )\n",
    "        p_df[ 'hfl_coupling_class' + v ] = le_yn_none.transform( p_df[ 'hfl_coupling_class' + v ] )\n",
    "        p_df[ 'hfl_material' + v ] = le_yn_none.transform( p_df[ 'hfl_material' + v ] )\n",
    "        p_df[ 'hfl_plating' + v ] = le_yn_none.transform( p_df[ 'hfl_plating' + v ] )\n",
    "        p_df[ 'hfl_orientation' + v ] = le_yn_none.transform( p_df[ 'hfl_orientation' + v ] )\n",
    "\n",
    "        p_df[ 'nut_blind_hole' + v ] = le_yn_none.transform( p_df[ 'nut_blind_hole' + v ] )\n",
    "        p_df[ 'nut_orientation' + v ] = le_yn_none.transform( p_df[ 'nut_orientation' + v ] )\n",
    "\n",
    "        p_df[ 'sleeve_connection_type_id' + v ] = le_connection.transform( p_df[ 'sleeve_connection_type_id' + v ] )    \n",
    "        p_df[ 'sleeve_unique_feature' + v ] = le_yn_none.transform( p_df[ 'sleeve_unique_feature' + v ] )\n",
    "        p_df[ 'sleeve_plating' + v ] = le_yn_none.transform( p_df[ 'sleeve_plating' + v ] )\n",
    "        p_df[ 'sleeve_orientation' + v ] = le_yn_none.transform( p_df[ 'sleeve_orientation' + v ] )\n",
    "\n",
    "\n",
    "        p_df[ 'straight_mj_class_code' + v ] = le_elbow_mj_class_code.transform( p_df[ 'straight_mj_class_code' + v ] )\n",
    "        p_df[ 'straight_groove' + v ] = le_yn_none.transform( p_df[ 'straight_groove' + v ] )\n",
    "        p_df[ 'straight_unique_feature' + v ] = le_yn_none.transform( p_df[ 'straight_unique_feature' + v ] )\n",
    "        p_df[ 'straight_orientation' + v ] = le_yn_none.transform( p_df[ 'straight_orientation' + v ] )\n",
    "\n",
    "\n",
    "        p_df[ 'tee_mj_class_code' + v ] = le_elbow_mj_class_code.transform( p_df[ 'tee_mj_class_code' + v ] )\n",
    "        p_df[ 'tee_mj_plug_class_code' + v ] = le_elbow_mj_class_code.transform( p_df[ 'tee_mj_plug_class_code' + v ] )\n",
    "        p_df[ 'tee_groove' + v ] = le_yn_none.transform( p_df[ 'tee_groove' + v ] )    \n",
    "        p_df[ 'tee_unique_feature' + v ] = le_yn_none.transform( p_df[ 'tee_unique_feature' + v ] )    \n",
    "        p_df[ 'tee_orientation' + v ] = le_yn_none.transform( p_df[ 'tee_orientation' + v ] )    \n",
    "\n",
    "        p_df[ 'threaded_end_form_id_1' + v ] = le_type_end.transform( p_df[ 'threaded_end_form_id_1' + v ] )\n",
    "        p_df[ 'threaded_connection_type_id_1' + v ] = le_connection.transform( p_df[ 'threaded_connection_type_id_1' + v ] )    \n",
    "        p_df[ 'threaded_end_form_id_2' + v ] = le_type_end.transform( p_df[ 'threaded_end_form_id_2' + v ] )\n",
    "        p_df[ 'threaded_connection_type_id_2' + v ] = le_connection.transform( p_df[ 'threaded_connection_type_id_2' + v ] )\n",
    "        p_df[ 'threaded_end_form_id_3' + v ] = le_type_end.transform( p_df[ 'threaded_end_form_id_3' + v ] )\n",
    "        p_df[ 'threaded_connection_type_id_3' + v ] = le_connection.transform( p_df[ 'threaded_connection_type_id_3' + v ] )\n",
    "        p_df[ 'threaded_end_form_id_4' + v ] = le_end.transform( p_df[ 'threaded_end_form_id_4' + v ] )\n",
    "        p_df[ 'threaded_connection_type_id_4' + v ] = le_connection.transform( p_df[ 'threaded_connection_type_id_4' + v ] )\n",
    "        p_df[ 'threaded_unique_feature' + v ] = le_yn_none.transform( p_df[ 'threaded_unique_feature' + v ] )\n",
    "        p_df[ 'threaded_orientation' + v ] = le_yn_none.transform( p_df[ 'threaded_orientation' + v ] )\n",
    "\n",
    "    return p_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Label Encoding용 Dataset\n",
    "* categorical data를 모두 포함해야 하므로, tube join후 기반으로 label encoder를 fitting한다\n",
    "* label encoding의 대상은 bracket_pricing, supplier, material_id, end_a_1x 시리즈, end_a 시리즈 feature이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 train/ test dataset merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train[ 'id' ] = 99999    # test와 join위해 feature 추가 : 99999는 train dataset이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_merged = df_train.append( df_test )    # train과 test df를 merge한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3.1 tube_bill_specs dataset merge 및 label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tube_bill_specs_end_comp = pd.read_csv( './dataset/03.merged/tube_bill_specs_end_comp_merged.csv' )\n",
    "# df_tube_bill_specs_end_comp = pd.read_csv( './dataset/03.merged/tube_bill_specs_end_merged.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged = df_merged.merge( df_tube_bill_specs_end_comp, how = 'inner', on = 'tube_assembly_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic = { 'Yes' : 'Y', 'No' : 'N' }\n",
    "df_merged[ 'bracket_pricing' ].replace( dic, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_is_annual( p_df ) :    # annual_usage 존재여부를 확인\n",
    "    is_annual = 'N'\n",
    "    if p_df[ 'annual_usage' ] > 0 :\n",
    "        is_annual = 'Y'\n",
    "    return is_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_merged[ 'is_annual' ] = df_merged.apply( get_is_annual, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min_order_quantity 조건테스트\n",
    "df_merged[ 'min_order_quantity' ].replace( to_replace = 0, value = 1, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_order_count( p_df, p_type ) :    # 주문횟수를 계산\n",
    "    order_count = 0\n",
    "    \n",
    "    if p_type == 'min' :\n",
    "        if ( p_df[ 'annual_usage' ] > 0 ) & ( p_df[ 'min_order_quantity' ] > 0 ) :\n",
    "            order_count = float( p_df[ 'annual_usage' ] / p_df[ 'min_order_quantity' ] )\n",
    "    elif p_type == 'quantity' :\n",
    "        order_count = float( p_df[ 'annual_usage' ] / p_df[ 'quantity' ] )\n",
    "    elif p_type == 'rule' :\n",
    "        if p_df[ 'bracket_pricing' ] == 'Y' :\n",
    "            order_count = float( p_df[ 'annual_usage' ] / p_df[ 'quantity' ] )\n",
    "        elif p_df[ 'bracket_pricing' ] == 'N' :\n",
    "            order_count = float( p_df[ 'annual_usage' ] / p_df[ 'min_order_quantity' ] )\n",
    "    elif p_type == 'sales' :\n",
    "        order_count = float( p_df[ 'annual_usage' ] * p_df[ 'quantity' ] )\n",
    "            \n",
    "    return order_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_merged[ 'order_count_by_min' ] = df_merged.apply( get_order_count, axis = 1, args = ('min',) )\n",
    "df_merged[ 'order_count_by_quantity' ] = df_merged.apply( get_order_count, axis = 1, args = ('quantity',) )\n",
    "df_merged[ 'order_count_by_rule' ] = df_merged.apply( get_order_count, axis = 1, args = ('rule',) )\n",
    "df_merged[ 'sales_result' ] = df_merged.apply( get_order_count, axis = 1, args = ('sales',) )\n",
    "df_merged = extract_year_month_day_from_quote_date( df_merged )    # feature 처리를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_merged[ 'date' ] = df_merged.apply( make_string_date, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_merged = executeLabelEncoding( df_merged, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['annual_usage', 'bracket_pricing', 'cost', 'id', 'min_order_quantity', 'quantity', 'quote_date', 'supplier', 'tube_assembly_id', 'material_id', 'diameter', 'wall', 'length', 'num_bends', 'bend_radius', 'end_a_1x', 'end_a_2x', 'end_x_1x', 'end_x_2x', 'end_a', 'end_x', 'num_boss', 'num_bracket', 'other', 'bend_num_by_radius', 'component_id_1', 'quantity_1', 'component_id_2', 'quantity_2', 'component_id_3', 'quantity_3', 'component_id_4', 'quantity_4', 'component_id_5', 'quantity_5', 'component_id_6', 'quantity_6', 'component_id_7', 'quantity_7', 'component_id_8', 'quantity_8', 'weight_sum', 'uniqueness_count', 'orientation_count', 'adaptor_sum', 'boss_sum', 'elbow_sum', 'float_sum', 'hfl_sum', 'nut_sum', 'other_sum', 'sleeve_sum', 'straight_sum', 'tee_sum', 'threaded_sum', 'adaptor_weight_sum', 'boss_weight_sum', 'elbow_weight_sum', 'float_weight_sum', 'hfl_weight_sum', 'nut_weight_sum', 'other_weight_sum', 'sleeve_weight_sum', 'straight_weight_sum', 'tee_weight_sum', 'threaded_weight_sum', 'comp_type_count', 'comp_total_count', 'tube_volume', 'spec1', 'spec2', 'spec3', 'spec4', 'spec5', 'spec6', 'spec7', 'spec8', 'spec9', 'spec10', 'spec_type_count', 'SP-0001', 'SP-0002', 'SP-0003', 'SP-0004', 'SP-0005', 'SP-0006', 'SP-0007', 'SP-0008', 'SP-0009', 'SP-0010', 'SP-0011', 'SP-0012', 'SP-0013', 'SP-0014', 'SP-0015', 'SP-0016', 'SP-0017', 'SP-0018', 'SP-0019', 'SP-0020', ...], dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_merged.to_csv( './dataset/df_train_test_tube_bill_specs_end_comp_merged_encoded.csv', index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.drop( 'id', axis = 1, inplace = True )    # 일단, 필요없는 것들 제거 : df_train을 원상 복구해둠\n",
    "del( df_test )    # 일단, 필요없는 것들 제거\n",
    "del( df_merged )    # 일단, 필요없는 것들 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.1 Merged features중, modeling시 제거할 feature 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_for_remove = []    # 전역변수의 선언\n",
    "def executeFeatureRemoval( p_df ) :\n",
    "    # 제거하고자 하는 feature list\n",
    "    global list_for_remove    # 전역변수 명시\n",
    "    \n",
    "    list_for_remove = [\n",
    "                        'tube_assembly_id',\n",
    "                        'quote_date',\n",
    "#                         'date',\n",
    "\n",
    "#                         'supplier',        \n",
    "#                         'annual_usage',\n",
    "#                         'min_order_quantity',\n",
    "#                         'bracket_pricing',\n",
    "        \n",
    "#                         'order_count_by_quantity',\n",
    "#                         'order_count_by_min',\n",
    "#                         'order_count_by_rule',\n",
    "#                         'sales_result',\n",
    "        \n",
    "        \n",
    "#                         'quantity',\n",
    "#                         'material_id',\n",
    "#                         'diameter',\n",
    "#                         'wall',\n",
    "#                         'length',\n",
    "#                         'num_bends',\n",
    "#                         'bend_radius',\n",
    "#                         'end_a_1x',\n",
    "#                         'end_a_2x',\n",
    "#                         'end_x_1x',\n",
    "#                         'end_x_2x',\n",
    "#                         'end_a',\n",
    "#                         'end_x',\n",
    "#                         'num_boss',\n",
    "#                         'num_bracket',\n",
    "#                         'other',\n",
    "        \n",
    "#                         'component_id_1',\n",
    "#                         'quantity_1',\n",
    "#                         'component_id_2',\n",
    "#                         'quantity_2',\n",
    "#                         'component_id_3',\n",
    "#                         'quantity_3',\n",
    "#                         'component_id_4',\n",
    "#                         'quantity_4',\n",
    "\n",
    "#                         'component_id_5',\n",
    "#                         'quantity_5',\n",
    "#                         'component_id_6',\n",
    "#                         'quantity_6',\n",
    "#                         'component_id_7',\n",
    "#                         'quantity_7',\n",
    "#                         'component_id_8',\n",
    "#                         'quantity_8',\n",
    "        \n",
    "#                         'weight_sum',\n",
    "#                         'adaptor_sum',\n",
    "#                         'boss_sum',\n",
    "#                         'elbow_sum',\n",
    "#                         'float_sum',\n",
    "#                         'hfl_sum',\n",
    "#                         'nut_sum',\n",
    "#                         'other_sum',\n",
    "#                         'sleeve_sum',\n",
    "#                         'straight_sum',\n",
    "#                         'tee_sum',\n",
    "#                         'threaded_sum',\n",
    "        \n",
    "#                         'adaptor_weight_sum',\n",
    "#                         'boss_weight_sum',\n",
    "#                         'elbow_weight_sum',\n",
    "#                         'float_weight_sum',\n",
    "#                         'hfl_weight_sum',\n",
    "#                         'nut_weight_sum',\n",
    "#                         'other_weight_sum',\n",
    "#                         'sleeve_weight_sum',\n",
    "#                         'straight_weight_sum',\n",
    "#                         'tee_weight_sum',\n",
    "#                         'threaded_weight_sum',\n",
    "        \n",
    "#                         'comp_type_count',\n",
    "#                         'comp_total_count',\n",
    "#                         'tube_volume',\n",
    "        \n",
    "#                         'spec1',\n",
    "#                         'spec2',\n",
    "#                         'spec3',\n",
    "#                         'spec4',\n",
    "#                         'spec5',\n",
    "        \n",
    "#                         'spec6',\n",
    "#                         'spec7',\n",
    "#                         'spec8',\n",
    "#                         'spec9',\n",
    "#                         'spec10',\n",
    "        \n",
    "#                         'spec_type_count',\n",
    "#                         'forming_x',\n",
    "#                         'forming_y',\n",
    "\n",
    "                        # component family 계열의 merge를 하지않은 case에 대한 feature들을 일단 죽여둔다\n",
    "                        'component_type_id',\n",
    "                        'mac475_weight',\n",
    "#                         'component_mac475',\n",
    "                        \n",
    "                        'uniqueness',\n",
    "                        'orientation',\n",
    "        \n",
    "                        'adaptor_adaptor_angle',\n",
    "                        'adaptor_overall_length',\n",
    "                        'adaptor_end_form_id_1',\n",
    "                        'adaptor_connection_type_id_1',\n",
    "                        'adaptor_length_1',\n",
    "                        'adaptor_thread_size_1',\n",
    "                        'adaptor_thread_pitch_1',\n",
    "                        'adaptor_nominal_size_1',\n",
    "                        'adaptor_end_form_id_2',\n",
    "                        'adaptor_connection_type_id_2',\n",
    "                        'adaptor_length_2',\n",
    "                        'adaptor_thread_size_2',\n",
    "                        'adaptor_thread_pitch_2',\n",
    "                        'adaptor_nominal_size_2',\n",
    "                        'adaptor_hex_size',\n",
    "                        'adaptor_unique_feature',\n",
    "                        'adaptor_orientation',\n",
    "                        'adaptor_weight',\n",
    "\n",
    "                        'boss_type',\n",
    "                        'boss_connection_type_id',\n",
    "                        'boss_outside_shape',\n",
    "                        'boss_base_type',\n",
    "                        'boss_height_over_tube',\n",
    "                        'boss_bolt_pattern_long',\n",
    "                        'boss_bolt_pattern_wide',\n",
    "                        'boss_groove',\n",
    "                        'boss_base_diameter',\n",
    "                        'boss_shoulder_diameter',\n",
    "                        'boss_unique_feature',\n",
    "                        'boss_orientation',\n",
    "                        'boss_weight',\n",
    "\n",
    "                        'elbow_bolt_pattern_long',\n",
    "                        'elbow_bolt_pattern_wide',\n",
    "                        'elbow_extension_length',\n",
    "                        'elbow_overall_length',\n",
    "                        'elbow_thickness',\n",
    "                        'elbow_drop_length',\n",
    "                        'elbow_elbow_angle',\n",
    "                        'elbow_mj_class_code',\n",
    "                        'elbow_mj_plug_class_code',\n",
    "                        'elbow_plug_diameter',\n",
    "                        'elbow_groove',\n",
    "                        'elbow_unique_feature',\n",
    "                        'elbow_orientation',\n",
    "                        'elbow_weight',\n",
    "\n",
    "                        'float_bolt_pattern_long',\n",
    "                        'float_bolt_pattern_wide',\n",
    "                        'float_thickness',\n",
    "                        'float_orientation',\n",
    "                        'float_weight',\n",
    "\n",
    "                        'hfl_hose_diameter',\n",
    "                        'hfl_corresponding_shell',\n",
    "                        'hfl_coupling_class',\n",
    "                        'hfl_material',\n",
    "                        'hfl_plating',\n",
    "                        'hfl_orientation',\n",
    "                        'hfl_weight',\n",
    "\n",
    "                        'nut_hex_nut_size',\n",
    "                        'nut_seat_angle',\n",
    "                        'nut_length',\n",
    "                        'nut_thread_size',\n",
    "                        'nut_thread_pitch',\n",
    "                        'nut_diameter',\n",
    "                        'nut_blind_hole',\n",
    "                        'nut_orientation',\n",
    "                        'nut_weight',\n",
    "\n",
    "                        'other_weight',\n",
    "\n",
    "                        'sleeve_connection_type_id',\n",
    "                        'sleeve_length',\n",
    "                        'sleeve_intended_nut_thread',\n",
    "                        'sleeve_intended_nut_pitch',\n",
    "                        'sleeve_unique_feature',\n",
    "                        'sleeve_plating',\n",
    "                        'sleeve_orientation',\n",
    "                        'sleeve_weight',\n",
    "\n",
    "                        'straight_bolt_pattern_long',\n",
    "                        'straight_bolt_pattern_wide',\n",
    "                        'straight_head_diameter',\n",
    "                        'straight_overall_length',\n",
    "                        'straight_thickness',\n",
    "                        'straight_mj_class_code',\n",
    "                        'straight_groove',\n",
    "                        'straight_unique_feature',\n",
    "                        'straight_orientation',\n",
    "                        'straight_weight',\n",
    "\n",
    "                        'tee_bolt_pattern_long',\n",
    "                        'tee_bolt_pattern_wide',\n",
    "                        'tee_extension_length',\n",
    "                        'tee_overall_length',\n",
    "                        'tee_thickness',\n",
    "                        'tee_drop_length',\n",
    "                        'tee_mj_class_code',\n",
    "                        'tee_mj_plug_class_code',\n",
    "                        'tee_groove',\n",
    "                        'tee_unique_feature',\n",
    "                        'tee_orientation',\n",
    "                        'tee_weight',\n",
    "\n",
    "                        'threaded_adaptor_angle',\n",
    "                        'threaded_overall_length',\n",
    "                        'threaded_hex_size',\n",
    "                        'threaded_end_form_id_1',\n",
    "                        'threaded_connection_type_id_1',\n",
    "                        'threaded_length_1',\n",
    "                        'threaded_thread_size_1',\n",
    "                        'threaded_thread_pitch_1',\n",
    "                        'threaded_nominal_size_1',\n",
    "                        'threaded_end_form_id_2',\n",
    "                        'threaded_connection_type_id_2',\n",
    "                        'threaded_length_2',\n",
    "                        'threaded_thread_size_2',\n",
    "                        'threaded_thread_pitch_2',\n",
    "                        'threaded_nominal_size_2',\n",
    "                        'threaded_end_form_id_3',\n",
    "                        'threaded_connection_type_id_3',\n",
    "                        'threaded_length_3',\n",
    "                        'threaded_thread_size_3',\n",
    "                        'threaded_thread_pitch_3',\n",
    "                        'threaded_nominal_size_3',\n",
    "                        'threaded_end_form_id_4',\n",
    "                        'threaded_connection_type_id_4',\n",
    "                        'threaded_length_4',\n",
    "                        'threaded_thread_size_4',\n",
    "                        'threaded_thread_pitch_4',\n",
    "                        'threaded_nominal_size_4',\n",
    "                        'threaded_unique_feature',\n",
    "                        'threaded_orientation',\n",
    "                        'threaded_weight',\n",
    "                      ]\n",
    "\n",
    "    return p_df.drop( list_for_remove, axis = 1, inplace = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.2 Train : 연/ 월/ 일 Feature 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = extract_year_month_day_from_quote_date( df_train )    # feature 처리를 수행\n",
    "df_train[ 'date' ] = df_train.apply( make_string_date, axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.3 Train : Tube와 merge통한 Feature 확장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_merged = df_train.merge( df_tube_bill_specs_end_comp, how = 'inner', on = 'tube_assembly_id' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.4 Train : Merged dataset Label Encoding 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_merged[ 'bracket_pricing' ].replace( dic, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_merged[ 'is_annual' ] = df_train_merged.apply( get_is_annual, axis = 1 )\n",
    "df_train_merged[ 'order_count_by_min' ] = df_train_merged.apply( get_order_count, axis = 1, args = ('min',) )\n",
    "df_train_merged[ 'order_count_by_quantity' ] = df_train_merged.apply( get_order_count, axis = 1, args = ('quantity',) )\n",
    "df_train_merged[ 'order_count_by_rule' ] = df_train_merged.apply( get_order_count, axis = 1, args = ('rule',) )\n",
    "df_train_merged[ 'sales_result' ] = df_train_merged.apply( get_order_count, axis = 1, args = ('sales',) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_merged[ 'req_comp_spec_type_count' ] = df_train_merged[ 'spec_type_count' ] + df_train_merged[ 'comp_type_count' ]\n",
    "df_train_merged[ 'req_comp_spec_total_count' ] = df_train_merged[ 'spec_type_count' ] + df_train_merged[ 'comp_type_count' ] * df_train_merged[ 'comp_total_count' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_merged.to_csv( './dataset/df_train_tube_bill_specs_end_comp_merged.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_merged = executeLabelEncoding( df_train_merged, is_init = False )    # label encoding을 수행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_merged.to_csv( './dataset/df_train_tube_bill_specs_end_comp_merged_encoded.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.5 Train : 불필요 Feature 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_merged = executeFeatureRemoval( df_train_merged )    # feature removal 처리를 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.6 Test : Dataset 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv( './dataset/test_set.csv' )    # data를 읽어들인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if bracket == 'Yes' :\n",
    "    # bracket_pricing == Yes인 경우만\n",
    "    df_test = df_test[ df_test[ 'bracket_pricing' ] == 'Yes' ]\n",
    "elif bracket == 'No' :\n",
    "    # bracket_pricing == No인 경우만\n",
    "    df_test = df_test[ df_test[ 'bracket_pricing' ] == 'No' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.7 Test : 연/ 월/ 일 Feature 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = extract_year_month_day_from_quote_date( df_test )    # feature 처리를 수행\n",
    "df_test[ 'date' ] = df_test.apply( make_string_date, axis = 1 )\n",
    "\n",
    "df_result = pd.DataFrame( df_test[ 'id' ], columns = ['id'] )    # 결과용 dataframe을 생성\n",
    "df_test.drop( 'id', axis = 1, inplace = True )    # id feature는 일단 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.8 Test : Tube와 merge통한 Feature 확장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_merged = df_test.merge( df_tube_bill_specs_end_comp, how = 'inner', on = 'tube_assembly_id' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.9 Test : Merged dataset Label Encoding 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_merged[ 'bracket_pricing' ].replace( dic, inplace = True )\n",
    "df_test_merged[ 'is_annual' ] = df_test_merged.apply( get_is_annual, axis = 1 )\n",
    "df_test_merged[ 'order_count_by_min' ] = df_test_merged.apply( get_order_count, axis = 1, args = ('min',) )\n",
    "df_test_merged[ 'order_count_by_quantity' ] = df_test_merged.apply( get_order_count, axis = 1, args = ('quantity',) )\n",
    "df_test_merged[ 'order_count_by_rule' ] = df_test_merged.apply( get_order_count, axis = 1, args = ('rule',) )\n",
    "df_test_merged[ 'sales_result' ] = df_test_merged.apply( get_order_count, axis = 1, args = ('sales',) )\n",
    "\n",
    "df_test_merged[ 'req_comp_spec_type_count' ] = df_test_merged[ 'spec_type_count' ] + df_test_merged[ 'comp_type_count' ]\n",
    "df_test_merged[ 'req_comp_spec_total_count' ] = df_test_merged[ 'spec_type_count' ] + df_test_merged[ 'comp_type_count' ] * df_test_merged[ 'comp_total_count' ]\n",
    "\n",
    "df_test_merged = executeLabelEncoding( df_test_merged, is_init = False )    # label encoding을 수행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tube_assembly_id      3956\n",
       "supplier              3956\n",
       "quote_date            3956\n",
       "annual_usage          3956\n",
       "min_order_quantity    3956\n",
       "bracket_pricing       3956\n",
       "quantity              3956\n",
       "year                  3956\n",
       "month                 3956\n",
       "day                   3956\n",
       "date                  3956\n",
       "material_id           3956\n",
       "diameter              3956\n",
       "wall                  3956\n",
       "length                3956\n",
       "...\n",
       "threaded_connection_type_id_4    3956\n",
       "threaded_length_4                3956\n",
       "threaded_thread_size_4           3956\n",
       "threaded_thread_pitch_4          3956\n",
       "threaded_nominal_size_4          3956\n",
       "threaded_unique_feature          3956\n",
       "threaded_orientation             3956\n",
       "threaded_weight                  3956\n",
       "is_annual                        3956\n",
       "order_count_by_min               3956\n",
       "order_count_by_quantity          3956\n",
       "order_count_by_rule              3956\n",
       "sales_result                     3956\n",
       "req_comp_spec_type_count         3956\n",
       "req_comp_spec_total_count        3956\n",
       "Length: 319, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_merged.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.10 Test : 불필요 Featrue 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_merged = executeFeatureRemoval( df_test_merged )    # feature removal 처리를 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# log함수 적용 테스트\n",
    "# X[ 'tube_volume' ] = np.log10( X[ 'tube_volume' ] )\n",
    "# df_test_merged[ 'tube_volume' ] = np.log10( df_test_merged[ 'tube_volume' ] )\n",
    "\n",
    "# bend nub으로 인한 tube의 복잡도 추정 feature의 추가\n",
    "df_train_merged[ 'bend_num_X_volume' ] = df_train_merged[ 'num_bends' ].replace( 0, 1 ) * df_train_merged[ 'tube_volume' ]\n",
    "df_test_merged[ 'bend_num_X_volume' ] = df_test_merged[ 'num_bends' ].replace( 0, 1 ) * df_test_merged[ 'tube_volume' ]\n",
    "\n",
    "df_train_merged[ 'bend_num_X_length' ] = df_train_merged[ 'num_bends' ].replace( 0, 1 ) * df_train_merged[ 'length' ]\n",
    "df_test_merged[ 'bend_num_X_length' ] = df_test_merged[ 'num_bends' ].replace( 0, 1 ) * df_test_merged[ 'length' ]\n",
    "\n",
    "df_train_merged[ 'bend_num_X_diameter' ] = df_train_merged[ 'num_bends' ].replace( 0, 1 ) * df_train_merged[ 'diameter' ]\n",
    "df_test_merged[ 'bend_num_X_diameter' ] = df_test_merged[ 'num_bends' ].replace( 0, 1 ) * df_test_merged[ 'diameter' ]\n",
    "\n",
    "df_train_merged[ 'bend_num_X_wall' ] = df_train_merged[ 'num_bends' ].replace( 0, 1 ) * df_train_merged[ 'wall' ]\n",
    "df_test_merged[ 'bend_num_X_wall' ] = df_test_merged[ 'num_bends' ].replace( 0, 1 ) * df_test_merged[ 'wall' ]\n",
    "\n",
    "# df_train_merged[ 'bend_num_X_quantity' ] = df_train_merged[ 'num_bends' ].replace( 0, 1 ) * df_train_merged[ 'quantity' ]\n",
    "# df_test_merged[ 'bend_num_X_quantity' ] = df_test_merged[ 'num_bends' ].replace( 0, 1 ) * df_test_merged[ 'quantity' ]\n",
    "\n",
    "# df_train_merged[ 'bend_num_by_radius_x_volume' ] = df_train_merged[ 'bend_num_by_radius' ].replace( 0, 1 ) * df_train_merged[ 'tube_volume' ]\n",
    "# df_test_merged[ 'bend_num_by_radius_x_volume' ] = df_test_merged[ 'bend_num_by_radius' ].replace( 0, 1 ) * df_test_merged[ 'tube_volume' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # quantity 관계고려하여 feature value 조정\n",
    "# for i in range( 1, 9 ) :\n",
    "#     df_train_merged[ 'quantity_' + str( i ) ] = df_train_merged[ 'quantity_' + str( i ) ] * df_train_merged[ 'quantity' ]\n",
    "#     df_test_merged[ 'quantity_' + str( i ) ] = df_test_merged[ 'quantity_' + str( i ) ] * df_test_merged[ 'quantity' ]\n",
    "    \n",
    "# list_to_multiply_with_quantity = [\n",
    "#     'weight_sum',\n",
    "\n",
    "#     'uniqueness_count',\n",
    "#     'orientation_count',\n",
    "\n",
    "#     'adaptor_sum',\n",
    "#     'boss_sum',\n",
    "#     'elbow_sum',\n",
    "#     'float_sum',\n",
    "#     'hfl_sum',\n",
    "#     'nut_sum',\n",
    "#     'other_sum',\n",
    "#     'sleeve_sum',\n",
    "#     'straight_sum',\n",
    "#     'tee_sum',\n",
    "#     'threaded_sum',\n",
    "\n",
    "#     'adaptor_weight_sum',\n",
    "#     'boss_weight_sum',\n",
    "#     'elbow_weight_sum',\n",
    "#     'float_weight_sum',\n",
    "#     'hfl_weight_sum',\n",
    "#     'nut_weight_sum',\n",
    "#     'other_weight_sum',\n",
    "#     'sleeve_weight_sum',\n",
    "#     'straight_weight_sum',\n",
    "#     'tee_weight_sum',\n",
    "#     'threaded_weight_sum',\n",
    "\n",
    "#     'comp_type_count',\n",
    "#     'comp_total_count',\n",
    "\n",
    "#     'tube_volume',\n",
    "\n",
    "#     'spec_type_count',\n",
    "\n",
    "#     'req_comp_spec_type_count',\n",
    "#     'req_comp_spec_total_count',\n",
    "# ]\n",
    "\n",
    "# for t in list_to_multiply_with_quantity :\n",
    "#     df_train_merged[ t ] = df_train_merged[ t ] * df_train_merged[ 'quantity' ]\n",
    "#     df_test_merged[ t ] = df_test_merged[ t ] * df_test_merged[ 'quantity' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_to_log = [ 'tube_volume', 'bend_num_X_volume', 'bend_num_X_length', 'bend_num_X_diameter', 'bend_num_X_wall',\n",
    "#                 'bend_num_X_quantity',    # 좋지않음\n",
    "#                 'bend_num_by_radius_x_volume',    # 좋지않음\n",
    "#                 'supplier_total_sales_result', 'supplier_annual_sales_result',    # 좋지않음\n",
    "#                 'material_total_sales_result', 'material_annual_sales_result',    # 좋지않음\n",
    "              ]\n",
    "\n",
    "# log함수 적용 테스트\n",
    "# X[ 'tube_volume' ] = np.log10( X[ 'tube_volume' ] )\n",
    "# df_test_merged[ 'tube_volume' ] = np.log10( df_test_merged[ 'tube_volume' ] )\n",
    "\n",
    "# df_train_merged[ 'bend_num_by_radius_x_volume' ] = df_train_merged[ 'bend_num_by_radius' ].replace( 0, 1 ) * df_train_merged[ 'tube_volume' ]\n",
    "# df_test_merged[ 'bend_num_by_radius_x_volume' ] = df_test_merged[ 'bend_num_by_radius' ].replace( 0, 1 ) * df_test_merged[ 'tube_volume' ]\n",
    "\n",
    "for feat in list_to_log :\n",
    "    df_train_merged[ feat ].replace( to_replace = 0, value = 1, inplace = True )\n",
    "    df_test_merged[ feat ].replace( to_replace = 0, value = 1, inplace = True )\n",
    "    \n",
    "    df_train_merged[ feat ] = np.log10( df_train_merged[ feat ] )\n",
    "    df_test_merged[ feat ] = np.log10( df_test_merged[ feat ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if bracket != 'All' :\n",
    "    df_train_merged.drop( 'bracket_pricing', axis = 1, inplace = False )\n",
    "    df_test_merged.drop( 'bracket_pricing', axis = 1, inplace = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4.11 Prediction Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_train_merged.drop( 'cost', axis = 1, inplace = False )    # X를 확보\n",
    "y = np.log1p( df_train_merged[ 'cost' ] )   # y를 확보\n",
    "\n",
    "del( df_train )\n",
    "del( df_train_merged )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_cnt = 10    # cv : cross validation 횟수\n",
    "n_jobs_cnt = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if mode == True :\n",
    "    model_list = [\n",
    "#                    RandomForestRegressor(),    # 제출용\n",
    "                   GradientBoostingRegressor( n_estimators = 2500,\n",
    "                                              max_depth = 7,\n",
    "                                              warm_start = True,\n",
    "                                              subsample = 0.8\n",
    "                                            ),\n",
    "                 ]\n",
    "else :\n",
    "    model_list = [\n",
    "#                    RandomForestRegressor(),    # 테스트용\n",
    "                   GradientBoostingRegressor(),    # 테스트용\n",
    "                 ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "model :  GradientBoostingRegressor\n",
      "best_score :  0.775010664134\n",
      "=================\n",
      "best model :  GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
      "             max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=2500,\n",
      "             random_state=None, subsample=0.8, verbose=0, warm_start=True)\n",
      "=================\n",
      "                      features  importance\n",
      "70                       spec2   11.586090\n",
      "189            bend_num_X_wall    9.642076\n",
      "186          bend_num_X_volume    9.041565\n",
      "187          bend_num_X_length    8.459423\n",
      "8                         date    7.881868\n",
      "7                          day    6.692056\n",
      "29              component_id_3    6.432663\n",
      "68                 tube_volume    3.675587\n",
      "12                      length    2.815673\n",
      "9                  material_id    2.376031\n",
      "25              component_id_1    2.158150\n",
      "183               sales_result    2.121031\n",
      "41                  weight_sum    2.036604\n",
      "27              component_id_2    1.974640\n",
      "61            other_weight_sum    1.517545\n",
      "181    order_count_by_quantity    1.349307\n",
      "180         order_count_by_min    1.256728\n",
      "182        order_count_by_rule    1.251638\n",
      "1                 annual_usage    1.115824\n",
      "188        bend_num_X_diameter    1.108477\n",
      "24          bend_num_by_radius    1.059425\n",
      "19                       end_a    1.010279\n",
      "13                   num_bends    0.952605\n",
      "176                  forming_x    0.784976\n",
      "100                    SP-0021    0.735449\n",
      "6                        month    0.727748\n",
      "69                       spec1    0.667496\n",
      "2           min_order_quantity    0.651703\n",
      "0                     supplier    0.622593\n",
      "185  req_comp_spec_total_count    0.541648\n",
      "..                         ...         ...\n",
      "90                     SP-0011    0.000000\n",
      "93                     SP-0014    0.000000\n",
      "82                     SP-0003    0.000000\n",
      "97                     SP-0018    0.000000\n",
      "98                     SP-0019    0.000000\n",
      "80                     SP-0001    0.000000\n",
      "102                    SP-0023    0.000000\n",
      "106                    SP-0027    0.000000\n",
      "78                      spec10    0.000000\n",
      "110                    SP-0031    0.000000\n",
      "111                    SP-0032    0.000000\n",
      "113                    SP-0034    0.000000\n",
      "118                    SP-0039    0.000000\n",
      "119                    SP-0040    0.000000\n",
      "120                    SP-0041    0.000000\n",
      "121                    SP-0042    0.000000\n",
      "123                    SP-0044    0.000000\n",
      "124                    SP-0045    0.000000\n",
      "125                    SP-0046    0.000000\n",
      "127                    SP-0048    0.000000\n",
      "128                    SP-0049    0.000000\n",
      "133                    SP-0054    0.000000\n",
      "135                    SP-0056    0.000000\n",
      "64              tee_weight_sum    0.000000\n",
      "85                     SP-0006    0.000000\n",
      "143                    SP-0064    0.000000\n",
      "153                    SP-0074    0.000000\n",
      "154                    SP-0075    0.000000\n",
      "155                    SP-0076    0.000000\n",
      "109                    SP-0030    0.000000\n",
      "\n",
      "[190 rows x 2 columns]\n",
      "Wall time: 12min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "for model in model_list :\n",
    "    model_name = str( model ).split( '(' )[0]    # 파일생성용\n",
    "    \n",
    "    if model_name.startswith( 'GradientBoostingRegressor' ) :\n",
    "        params = {\n",
    "    #                'n_estimators' : (1500,2000,2500,3000),\n",
    "    #                'max_depth' : (5,7,9),\n",
    "#                    'subsample' : (1.0,0.9,0.8,0.7)\n",
    "                 }\n",
    "    elif model_name.startswith( 'RandomForestRegressor' ) :\n",
    "        params = {\n",
    "                 }        \n",
    "\n",
    "    gs = grid_search.GridSearchCV( model,\n",
    "                                   param_grid = params,\n",
    "                                   n_jobs = n_jobs_cnt,\n",
    "                                   cv = cv_cnt,\n",
    "                                 )\n",
    "    gs.fit( X, y )\n",
    "    \n",
    "    print( '=========================================' )\n",
    "    print( 'model : ', str( model ).split( '(' )[0] )\n",
    "    print( 'best_score : ', gs.best_score_ )\n",
    "    \n",
    "    print( '=================' )\n",
    "    print( 'best model : ', gs.best_estimator_ )\n",
    "    print( '=================' )\n",
    "    \n",
    "    df_feature_importance = pd.DataFrame( X.columns.values, columns = [ 'features' ] )\n",
    "    df_feature_importance[ 'importance' ] = gs.best_estimator_.feature_importances_ * 100\n",
    "    print( df_feature_importance.sort( 'importance', ascending = False  ) )    \n",
    "    \n",
    "    \n",
    "    y_pred = gs.best_estimator_.predict( df_test_merged )    # prediction 수행\n",
    "    df_result[ 'cost' ] = np.expm1( y_pred )\n",
    "    \n",
    "    now = time.strftime( '%Y%m%d%H%M%S' )    # 현재시각을 확보\n",
    "    file_timestamp = now[2:4] + now[4:6] + now[6:8] + now[8:10] + now[10:12] + now[12:14]\n",
    "    accuracy = '{0:.1f}%'.format( gs.best_score_ * 100 )    # latitude에 대한 예측률 저장 : 파일명 활용용도임\n",
    "    \n",
    "    if bracket == 'Yes' :\n",
    "        df_result.to_csv( path_or_buf = './result.to.submit/' + file_timestamp + '.' + model_name +\n",
    "                          '.' + accuracy + '.result().bracket.Y.csv', sep = ',', index = False )\n",
    "    elif bracket == 'No' :\n",
    "        df_result.to_csv( path_or_buf = './result.to.submit/' + file_timestamp + '.' + model_name +\n",
    "                          '.' + accuracy + '.result().bracket.N.csv', sep = ',', index = False )\n",
    "    elif bracket == 'All' :\n",
    "        df_result.to_csv( path_or_buf = './result.to.submit/' + file_timestamp + '.' + model_name +\n",
    "                          '.' + accuracy + '.result().bracket.All.csv', sep = ',', index = False )                \n",
    "    \n",
    "    \n",
    "    list_features = df_test_merged.columns.values.tolist()    \n",
    "    \n",
    "    with open( 'performance.condition.history.txt', 'a' ) as history_file :    # 모델의 이력을 logging\n",
    "        history_file.write( '======================================================================\\n' )\n",
    "        history_file.write( '0. Description :\\n' )\n",
    "        if mode == True :\n",
    "            history_file.write( '\\tmode : Production mode\\n' )\n",
    "        else :\n",
    "            history_file.write( '\\tmode : Test mode\\n' )\n",
    "        history_file.write( '1. File name :\\n\\t' + file_timestamp + '.' + model_name + '.' + accuracy + '\\n' )\n",
    "        history_file.write( '2. Model information :\\n\\t' + str( gs.best_estimator_ ) + '\\n' )\n",
    "        history_file.write( '3. Applied features :\\n' )\n",
    "        for feature in list_features :\n",
    "            history_file.write( '\\t' + feature + '\\n' )\n",
    "        history_file.write( '4. Removed features :\\n' )\n",
    "        for feature in list_for_remove :\n",
    "            history_file.write( '\\t' + feature + '\\n' )\n",
    "        history_file.write( '5. Feature importance :\\n\\t' )        \n",
    "        history_file.write( df_feature_importance.sort( 'importance', ascending = False  ).to_string() )\n",
    "        history_file.write( '\\n' )\n",
    "        history_file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td> 41</td>\n",
       "      <td>  7.996248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td> 42</td>\n",
       "      <td> 48.591876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td> 55</td>\n",
       "      <td>  7.892302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       cost\n",
       "40  41   7.996248\n",
       "41  42  48.591876\n",
       "54  55   7.892302"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head( 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>    8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>  616.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td> 1383.602416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>    0.495316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>    6.959094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>   17.925937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>  249.967230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td> 3956.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cost\n",
       "count     8.000000\n",
       "mean    616.002910\n",
       "std    1383.602416\n",
       "min       0.495316\n",
       "25%       6.959094\n",
       "50%      17.925937\n",
       "75%     249.967230\n",
       "max    3956.000000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_desc = df_result.describe()    # 결과의 overview 확인\n",
    "df_result_desc.drop( 'id', axis = 1, inplace = True )\n",
    "df_result_desc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del( X )\n",
    "del( y )\n",
    "del( df_test )\n",
    "del( df_test_merged )\n",
    "del( df_components )\n",
    "del( df_result_desc )\n",
    "del( df_result )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
